#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSASI ìƒë‹´ ê°€ì´ë“œ ë°ì´í„° ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸
Oracle DB â†’ Embedding â†’ Elasticsearch
"""

import oracledb
import requests
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
from datetime import datetime
import os
import re

# ì„¤ì •
ORACLE_CONFIG = {
    'user': 'DEVSSG',
    'password': 'd2vssg12#',
    'host': '10.203.7.71',
    'port': 1538,
    'service_name': 'DEVUTFDB'
}

ES_HOST = 'http://localhost:9200'
EMBEDDING_API_URL = 'http://localhost:5001/embed'
INDEX_NAME = 'csasi_consultation'

# Elasticsearch ì—°ê²°
es = Elasticsearch([ES_HOST])

def clean_html(text):
    """HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', ' ', text)
    # HTML ì—”í‹°í‹° ë³€í™˜
    text = text.replace('&nbsp;', ' ')
    text = text.replace('&lt;', '<')
    text = text.replace('&gt;', '>')
    text = text.replace('&amp;', '&')
    text = text.replace('&quot;', '"')
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text

def get_embedding(text):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
    try:
        response = requests.post(
            EMBEDDING_API_URL,
            json={'text': text},
            timeout=30
        )
        response.raise_for_status()
        return response.json()['vector']
    except Exception as e:
        print(f"âŒ ë²¡í„° ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def fetch_csasi_data():
    """Oracleì—ì„œ CSASI ë°ì´í„° ì¡°íšŒ"""
    print("ğŸ“Š Oracle DBì—ì„œ ë°ì´í„° ì¡°íšŒ ì¤‘...")
    
    connection = oracledb.connect(**ORACLE_CONFIG)
    cursor = connection.cursor()
    
    # CSASI ë°ì´í„° ì¡°íšŒ
    sql = """
    SELECT 
        c.CSASI_ID,
        c.CSASI_NM,
        c.CSASI_BRWS_CNT,
        c.USE_YN,
        c.REG_DTS,
        p.CSASI_PROP_ID,
        p.CSASI_PROP_TYPE_CD,
        pc.CSASI_PROP_SEQ,
        pc.CSASI_PROP_CNTT
    FROM SSG.CSASI c
    LEFT JOIN SSG.CSASI_PROP p ON c.CSASI_ID = p.CSASI_ID
    LEFT JOIN SSG.CSASI_PROP_CNTT pc ON p.CSASI_PROP_ID = pc.CSASI_PROP_ID
    WHERE c.USE_YN = 'Y'
    ORDER BY c.CSASI_ID, p.CSASI_PROP_ID, pc.CSASI_PROP_SEQ
    """
    
    cursor.execute(sql)
    rows = cursor.fetchall()
    
    cursor.close()
    connection.close()
    
    print(f"âœ… {len(rows)}ê±´ì˜ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
    return rows

def group_csasi_data(rows):
    """CSASI ë°ì´í„°ë¥¼ ê·¸ë£¹í™”"""
    print("ğŸ”„ ë°ì´í„° ê·¸ë£¹í™” ì¤‘...")
    
    csasi_dict = {}
    
    for row in rows:
        (csasi_id, csasi_nm, brws_cnt, use_yn, reg_dts,
         prop_id, prop_type_cd, prop_seq, prop_cntt) = row
        
        # CSASI ê¸°ë³¸ ì •ë³´
        if csasi_id not in csasi_dict:
            csasi_dict[csasi_id] = {
                'csasi_id': csasi_id,
                'csasi_name': csasi_nm,
                'browse_count': brws_cnt if brws_cnt else 0,
                'use_yn': use_yn,
                'reg_dts': reg_dts.strftime('%Y-%m-%d %H:%M:%S') if reg_dts else None,
                'properties': []
            }
        
        # ì†ì„± ì •ë³´ ì¶”ê°€
        if prop_id and prop_cntt:
            csasi_dict[csasi_id]['properties'].append({
                'prop_id': prop_id,
                'prop_type_cd': prop_type_cd,
                'prop_seq': prop_seq,
                'content': clean_html(prop_cntt)
            })
    
    csasi_list = list(csasi_dict.values())
    print(f"âœ… {len(csasi_list)}ê°œì˜ ìƒë‹´ ê°€ì´ë“œë¡œ ê·¸ë£¹í™” ì™„ë£Œ")
    return csasi_list

def create_documents(csasi_list):
    """Elasticsearch ë¬¸ì„œ ìƒì„± (ë²¡í„°í™” í¬í•¨)"""
    print("ğŸ”¨ Elasticsearch ë¬¸ì„œ ìƒì„± ì¤‘...")
    
    documents = []
    total = len(csasi_list)
    
    for idx, csasi in enumerate(csasi_list, 1):
        # ì „ì²´ ë‚´ìš© ìƒì„± (ë²¡í„°í™”ìš©)
        full_content_parts = [csasi['csasi_name']]
        
        for prop in csasi['properties']:
            if prop['content']:
                full_content_parts.append(prop['content'])
        
        full_content = ' '.join(full_content_parts)
        
        # ë²¡í„° ìƒì„±
        print(f"  [{idx}/{total}] {csasi['csasi_id']}: {csasi['csasi_name'][:30]}... ë²¡í„°í™” ì¤‘...", end='')
        
        vector = get_embedding(full_content)
        
        if vector is None:
            print(" âŒ ì‹¤íŒ¨")
            continue
        
        print(" âœ…")
        
        # Elasticsearch ë¬¸ì„œ ìƒì„±
        doc = {
            '_index': INDEX_NAME,
            '_id': csasi['csasi_id'],
            'csasi_id': csasi['csasi_id'],
            'csasi_name': csasi['csasi_name'],
            'browse_count': csasi['browse_count'],
            'properties': csasi['properties'],
            'full_content': full_content,
            'content_vector': vector,
            'use_yn': csasi['use_yn'],
            'reg_dts': csasi['reg_dts'],
            'indexed_at': datetime.now().isoformat()
        }
        
        documents.append(doc)
    
    print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
    return documents

def index_documents(documents):
    """Elasticsearchì— ë¬¸ì„œ ì¸ë±ì‹±"""
    print("ğŸ“¤ Elasticsearchì— ë°ì´í„° ì¸ë±ì‹± ì¤‘...")
    
    success, failed = bulk(es, documents, raise_on_error=False)
    
    print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ: ì„±ê³µ {success}ê±´, ì‹¤íŒ¨ {len(failed)}ê±´")
    
    if failed:
        print("âŒ ì‹¤íŒ¨í•œ ë¬¸ì„œ:")
        for item in failed[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"  - {item}")
    
    return success, failed

def verify_indexing():
    """ì¸ë±ì‹± ê²°ê³¼ í™•ì¸"""
    print("\nğŸ” ì¸ë±ì‹± ê²°ê³¼ í™•ì¸ ì¤‘...")
    
    # ì¸ë±ìŠ¤ í†µê³„
    stats = es.indices.stats(index=INDEX_NAME)
    doc_count = stats['indices'][INDEX_NAME]['total']['docs']['count']
    
    print(f"âœ… ì´ ë¬¸ì„œ ìˆ˜: {doc_count}ê±´")
    
    # ìƒ˜í”Œ ë¬¸ì„œ ì¡°íšŒ
    result = es.search(
        index=INDEX_NAME,
        body={
            "size": 3,
            "query": {"match_all": {}},
            "sort": [{"browse_count": {"order": "desc"}}]
        }
    )
    
    print(f"\nğŸ“„ ì¸ê¸° ìƒë‹´ ê°€ì´ë“œ TOP 3:")
    for hit in result['hits']['hits']:
        doc = hit['_source']
        print(f"  - {doc['csasi_name']} (ì¡°íšŒìˆ˜: {doc['browse_count']})")
        print(f"    ì†ì„± ìˆ˜: {len(doc['properties'])}ê°œ")
        print(f"    ë²¡í„° ì°¨ì›: {len(doc['content_vector'])}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ CSASI ìƒë‹´ ê°€ì´ë“œ ì¸ë±ì‹± ì‹œì‘")
    print("=" * 60)
    
    try:
        # 1. ë°ì´í„° ì¡°íšŒ
        rows = fetch_csasi_data()
        
        # 2. ë°ì´í„° ê·¸ë£¹í™”
        csasi_list = group_csasi_data(rows)
        
        # 3. ë¬¸ì„œ ìƒì„± (ë²¡í„°í™”)
        documents = create_documents(csasi_list)
        
        # 4. ì¸ë±ì‹±
        success, failed = index_documents(documents)
        
        # 5. ê²€ì¦
        verify_indexing()
        
        print("\n" + "=" * 60)
        print("âœ… ì¸ë±ì‹± ì™„ë£Œ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()

